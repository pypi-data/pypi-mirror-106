Metadata-Version: 1.1
Name: TFModelQuantizer
Version: 0.1
Summary: A Tensorflow TensorRT Model Quantizer for FP32 ,FP16 and calibrated INT8 model quantization.Runs on TensorRT default calibration on frozen model graphs for faster inference
Home-page: https://github.com/abhilash1910/TFModelQuantizer
Author: ABHILASH MAJUMDER
Author-email: debabhi1396@gmail.com
License: MIT
Download-URL: https://github.com/abhilash1910/TFModelQuantizer/archive/v_01.tar.gz
Description: UNKNOWN
Keywords: Tensorflow Quantizer,TensorRT Inference,FP32,FP16,INT8,GraphConverter,Calibrated Inference
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Build Tools
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
